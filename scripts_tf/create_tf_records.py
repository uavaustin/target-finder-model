# Adapted from https://github.com/tensorflow/models/blob/master/research/object_detection/dataset_tools/create_coco_tf_record.py
# Copyright 2017 The TensorFlow Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================
"""
AFTER running create_full_images.py and create_detection_data.py:

$ python scripts_tf/create_tf_records.py --image_dir ./scripts_generate/data
"""
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import hashlib
import io
import json
import os
import contextlib2
import numpy as np
from PIL import Image
import glob

import tensorflow as tf

from object_detection.dataset_tools import tf_record_creation_util
from object_detection.utils import dataset_util

with open(os.path.join(os.path.dirname(__file__), 
        os.pardir, 'config.yaml'), 'r') as stream:
    import yaml
    config = yaml.safe_load(stream)

CLASSES = config['classes']['shapes'] + config['classes']['alphas']

flags = tf.app.flags
tf.flags.DEFINE_string('image_dir', '',
                       'Training image directory.')
tf.flags.DEFINE_string('output_dir', 'model_data', 'Output data directory.')

FLAGS = flags.FLAGS

tf.logging.set_verbosity(tf.logging.INFO)


def parse_annotation_data(data):
  labels = []
  data = data.replace('\r', '').strip()
  for line in data.split('\n'):
    labels.append([float(val) for val in line.split(' ')])
  return labels


def create_tf_example(image_path_prefix, image_dir):
  """Converts image and txt annotations to a tf.Example proto.
  """
  image_id = os.path.basename(image_path_prefix)
  filename = image_path_prefix + '.jpeg'
  with tf.gfile.GFile(filename, 'rb') as fid:
      encoded_jpg = fid.read()
  encoded_jpg_io = io.BytesIO(encoded_jpg)
  image = Image.open(encoded_jpg_io)
  image_width, image_height = image.size

  image_format = b'jpeg'

  with open(image_path_prefix + '.txt', 'r') as annotations_fp:
    annotations = parse_annotation_data(annotations_fp.read())

  xmin = []
  xmax = []
  ymin = []
  ymax = []
  category_names = []
  category_ids = []
  
  for idx, (obj_id, cent_x, cent_y, w_prop, h_prop) in enumerate(annotations):

    w = w_prop * image_width
    h = h_prop * image_height
    x = (cent_x * image_width) - w // 2
    y = (cent_y * image_height) - h // 2

    xmin.append(float(x) / image_width)
    xmax.append(float(x + w) / image_width)
    ymin.append(float(y) / image_height)
    ymax.append(float(y + h) / image_height)

    category_id = int(obj_id)
    category_ids.append(category_id + 1)
    category_names.append(CLASSES[category_id].encode('utf8'))

  feature_dict = {
      'image/height':
          dataset_util.int64_feature(image_height),
      'image/width':
          dataset_util.int64_feature(image_width),
      'image/filename':
          dataset_util.bytes_feature(filename.encode('utf8')),
      'image/source_id':
          dataset_util.bytes_feature(image_id.encode('utf8')),
      'image/encoded':
          dataset_util.bytes_feature(encoded_jpg),
      'image/format':
          dataset_util.bytes_feature(image_format),
      'image/object/bbox/xmin':
          dataset_util.float_list_feature(xmin),
      'image/object/bbox/xmax':
          dataset_util.float_list_feature(xmax),
      'image/object/bbox/ymin':
          dataset_util.float_list_feature(ymin),
      'image/object/bbox/ymax':
          dataset_util.float_list_feature(ymax),
      'image/object/class/text':
          dataset_util.bytes_list_feature(category_names),
      'image/object/class/label': 
          dataset_util.int64_list_feature(category_ids)
  }
  example = tf.train.Example(features=tf.train.Features(feature=feature_dict))
  return example


def _create_tf_record_from_images(data_dir, output_path, num_shards):
  """Loads images generated by generate/*.py scripts and converts
  them into tf records.
  """
  with contextlib2.ExitStack() as tf_record_close_stack:

    output_tfrecords = tf_record_creation_util.open_sharded_output_tfrecords(
        tf_record_close_stack, output_path, num_shards)

    image_fns = glob.glob(os.path.join(data_dir, 'ex*.jpeg'))

    for idx, image_fn in enumerate(image_fns):
      if idx % 100 == 0:
        tf.logging.info('On image %d of %d', idx, len(image_fns))
      image_path_prefix = image_fn.replace('.jpeg', '')
      tf_example = create_tf_example(image_path_prefix, data_dir)
      shard_idx = idx % num_shards
      output_tfrecords[shard_idx].write(tf_example.SerializeToString())
    tf.logging.info('Finished writing.')


def main(_):
  assert FLAGS.image_dir, '`image_dir` missing.'
  assert FLAGS.output_dir, '`output_dir` missing.'

  if not tf.gfile.IsDirectory(FLAGS.output_dir):
    tf.gfile.MakeDirs(FLAGS.output_dir)

  train_output_path = os.path.join(FLAGS.output_dir, 'tfm_train.record')
  val_output_path = os.path.join(FLAGS.output_dir, 'tfm_val.record')

  _create_tf_record_from_images(
      os.path.join(FLAGS.image_dir, 'detector_train', 'images'),
      train_output_path,
      num_shards=10)

  _create_tf_record_from_images(
      os.path.join(FLAGS.image_dir, 'detector_val', 'images'),
      val_output_path,
      num_shards=2)


if __name__ == '__main__':
  tf.app.run()
			
