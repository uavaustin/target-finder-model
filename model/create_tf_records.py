# Adapted from https://github.com/tensorflow/models/blob/master/research/object_detection/dataset_tools/create_coco_tf_record.py
# Copyright 2017 The TensorFlow Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================

r"""Convert raw COCO dataset to TFRecord for object_detection.

Please note that this tool creates sharded output files.

Example usage:
    python create_coco_tf_record.py --logtostderr \
      --train_image_dir="${TRAIN_IMAGE_DIR}" \
      --val_image_dir="${VAL_IMAGE_DIR}" \
      --test_image_dir="${TEST_IMAGE_DIR}" \
      --train_annotations_file="${TRAIN_ANNOTATIONS_FILE}" \
      --val_annotations_file="${VAL_ANNOTATIONS_FILE}" \
      --testdev_annotations_file="${TESTDEV_ANNOTATIONS_FILE}" \
      --output_dir="${OUTPUT_DIR}"
"""
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import hashlib
import io
import json
import os
import contextlib2
import numpy as np
from PIL import Image
import glob

import tensorflow as tf

from object_detection.dataset_tools import tf_record_creation_util
from object_detection.utils import dataset_util


flags = tf.app.flags
tf.flags.DEFINE_string('image_dir', '',
                       'Training image directory.')
tf.flags.DEFINE_string('output_dir', 'tmp', 'Output data directory.')

FLAGS = flags.FLAGS

tf.logging.set_verbosity(tf.logging.INFO)


def parse_annotation_data(data):
  labels = []
  data = data.replace('\r', '').strip()
  for line in data.split('\n'):
    labels.append([float(val) for val in line.split(' ')])
  return labels


def create_tf_example(image_path_prefix, image_dir):
  """Converts image and txt annotations to a tf.Example proto.
  """
  print(image_path_prefix)

  image_id = os.path.basename(image_path_prefix)
  filename = image_path_prefix + '.png'
  image = Image.open(filename)
  image_height, image_width = image.size
  key = hashlib.sha256(image.tobytes()).hexdigest()

  with open(image_path_prefix + '.txt', 'r') as annotations_fp:
    annotations = parse_annotation_data(annotations_fp.read())

  print(annotations)

  xmin = []
  xmax = []
  ymin = []
  ymax = []
  category_names = []
  category_ids = []
  
  for (obj_id, cent_x, cent_y, w, h) in annotations:

    xmin.append(float(x) / image_width)
    xmax.append(float(x + width) / image_width)
    ymin.append(float(y) / image_height)
    ymax.append(float(y + height) / image_height)
    category_id = int(obj_id)
    category_ids.append(category_id)
    category_names.append(str(obj_id)) # todo look up name

  feature_dict = {
      'image/height':
          dataset_util.int64_feature(image_height),
      'image/width':
          dataset_util.int64_feature(image_width),
      'image/filename':
          dataset_util.bytes_feature(filename.encode('utf8')),
      'image/source_id':
          dataset_util.bytes_feature(image_id.encode('utf8')),
      'image/key/sha256':
          dataset_util.bytes_feature(key.encode('utf8')),
      'image/encoded':
          dataset_util.bytes_feature(image.tobytes()),
      'image/format':
          dataset_util.bytes_feature('png'.encode('utf8')),
      'image/object/bbox/xmin':
          dataset_util.float_list_feature(xmin),
      'image/object/bbox/xmax':
          dataset_util.float_list_feature(xmax),
      'image/object/bbox/ymin':
          dataset_util.float_list_feature(ymin),
      'image/object/bbox/ymax':
          dataset_util.float_list_feature(ymax),
      'image/object/class/text':
          dataset_util.bytes_list_feature(category_names)
  }
  example = tf.train.Example(features=tf.train.Features(feature=feature_dict))
  return key, example


def _create_tf_record_from_images(data_dir, output_path, num_shards):
  """Loads images generated by generate/*.py scripts and converts
  them into tf records.
  """
  with contextlib2.ExitStack() as tf_record_close_stack:

    output_tfrecords = tf_record_creation_util.open_sharded_output_tfrecords(
        tf_record_close_stack, output_path, num_shards)

    image_fns = glob.glob(os.path.join(data_dir, 'ex*.png'))

    for idx, image_fn in enumerate(image_fns):
      if idx % 100 == 0:
        tf.logging.info('On image %d of %d', idx, len(image_fns))
      image_path_prefix = image_fn.replace('.png', '')
      _, tf_example = create_tf_example(image_path_prefix, data_dir)
      shard_idx = idx % num_shards
      output_tfrecords[shard_idx].write(tf_example.SerializeToString())
    tf.logging.info('Finished writing.')


def main(_):
  assert FLAGS.image_dir, '`image_dir` missing.'

  if not tf.gfile.IsDirectory(FLAGS.output_dir):
    tf.gfile.MakeDirs(FLAGS.output_dir)

  train_output_path = os.path.join(FLAGS.output_dir, 'tfm_train.record')
  val_output_path = os.path.join(FLAGS.output_dir, 'tfm_val.record')

  _create_tf_record_from_images(
      os.path.join(FLAGS.image_dir, 'detector_train', 'images'),
      train_output_path,
      num_shards=2)

  _create_tf_record_from_images(
      os.path.join(FLAGS.image_dir, 'detector_val', 'images'),
      val_output_path,
      num_shards=2)


if __name__ == '__main__':
  tf.app.run()
			